{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "lecture3_activations.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xinmiaow/STAT545-UBC.github.io/blob/master/lecture3_activations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po9bojmORoTf",
        "colab_type": "text"
      },
      "source": [
        "# CPSC 533R lecture 3\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I983PjArRoTj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import standard PyTorch modules\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# import torchvision module to handle image manipulation\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bs3HNaKvCB1Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class myNN(nn.Module):\n",
        "  def __init__(self, in_features=28*28, latent_dim= 128, out_dim=100, activation_layer=nn.ReLU()):\n",
        "    # define a simple structure\n",
        "    super().__init__()\n",
        "    \n",
        "    self.in_features = in_features\n",
        "    self.out_dim = out_dim\n",
        "    self.latent_dim = latent_dim\n",
        "    self.activation_layer = activation_layer\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features=self.in_features, out_features=self.latent_dim)\n",
        "    self.fc2 = nn.Linear(in_features=self.latent_dim, out_features=out_dim)\n",
        "\n",
        "  def forward(self, batch):\n",
        "    x = batch.flatten(1,-1)\n",
        "    x = self.fc1(x)\n",
        "    x = self.activation_layer(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.activation_layer(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8R2uzHKMVKR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "2576d82d-04b4-42d7-8784-6b4c819a7efc"
      },
      "source": [
        "img_batch = torch.normal(0, 1, [10000,1,28,28]) # TODO: play here\n",
        "network = myNN(activation_layer=nn.ReLU())\n",
        "\n",
        "def analyze_features(self, input, output):\n",
        "   features = output[0].data\n",
        "   print('shape',features.shape, 'mean', features.mean(), 'std', features.std())\n",
        "\n",
        "# TODO: play here\n",
        "#torch.nn.init.kaiming_normal_(network.fc1.weight,  mode='fan_in', nonlinearity='relu')\n",
        "#network.fc1.bias.data *= 1\n",
        "\n",
        "network.fc1.register_forward_hook(analyze_features)\n",
        "network.activation_layer.register_forward_hook(analyze_features)\n",
        "network.fc2.register_forward_hook(analyze_features)\n",
        "\n",
        "pred = network(img_batch)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape torch.Size([128]) mean tensor(-0.0053) std tensor(0.5829)\n",
            "shape torch.Size([128]) mean tensor(0.2222) std tensor(0.3522)\n",
            "shape torch.Size([100]) mean tensor(-0.0374) std tensor(0.2360)\n",
            "shape torch.Size([100]) mean tensor(0.0755) std tensor(0.1266)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQFTSHz7HRRq",
        "colab_type": "text"
      },
      "source": [
        "# Repeat on real images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asZx8Ka6i0pO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "57fc2704-d858-43e9-8e2f-d61b7f47c006"
      },
      "source": [
        "train_set = torchvision.datasets.MNIST(\n",
        "    root = './DatasetFashionMNIST',\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        ")\n",
        "loader = torch.utils.data.DataLoader(train_set, batch_size = 8, num_workers=0)\n",
        "iterator = iter(loader)\n",
        "batch = next(iterator)\n",
        "print(batch[0].shape)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 1, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpcQWgYhUMrB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: play here\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}